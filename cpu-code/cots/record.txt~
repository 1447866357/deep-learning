
=====================================
                face
=====================================
*************************************
t1:lr3_l0.001.out
input_number:5000
n_epoch:50
alpha:0.35
ela:0.001
learning_rate:3
u:0.005
alpha_learning_rate:0.001
-------------------------------------
epoch:0
R_cost:18.1874  P_cost:7.9905   all_cost:26.1779
epoch:49
R_cost:1.72349  P_cost:5.87987  all_cost:7.60335
alpha:0.199893
全局特征不明显，特征收敛较慢

*************************************
t5: lr5_a0.35_l0.001.out
input_number:5000
n_epoch:50
alpha:0.35
ela:0.001
learning_rate:5
u:0.005
alpha_learning_rate:0.001
-------------------------------------
epoch:0
R_cost:18.3245  P_cost:8.09443  all_cost:26.4189
epoch:49
R_cost:1.65271  P_cost:5.80554  all_cost:7.45825
alpha:0.190848
epoch:303
R_cost:1.01551  P_cost:5.01585  all_cost:6.03136
alpha:0.159087
epoch:999
R_cost:0.666153 P_cost:4.52815  all_cost:5.1943
alpha:0.157451

*************************************
t6:lr3_l0.001.out
input_number:5000
n_epoch:1000
alpha:0.35
ela:0.001
learning_rate:3
u:0.005
alpha_learning_rate:0.001
-------------------------------------
epoch:0
R_cost:18.3566  P_cost:8.06015  all_cost:26.4167
epoch:49
R_cost:2.05158  P_cost:5.9755   all_cost:8.02708
alpha:0.199865
epoch:102
R_cost:1.35656  P_cost:5.52981  all_cost:6.88637
alpha:0.184206

*************************************
t7:lr5_a0.8_l0.001.out
input_number:5000
n_epoch:1000
alpha:0.8
ela:0.001
learning_rate:5
u:0.005
alpha_learning_rate:0.001
-------------------------------------
epoch:0
R_cost:105.979  P_cost:18.3408  all_cost:124.32
epoch:49
R_cost:1.46344  P_cost:6.03873  all_cost:7.50217
alpha:0.213023

*************************************
t8:lr3_a0.8_l0.001.out
input_number:5000
n_epoch:1000
alpha:0.8
ela:0.001
learning_rate:3
u:0.005
alpha_learning_rate:0.001
-------------------------------------
epoch:0
R_cost:105.58   P_cost:18.3208  all_cost:123.901
epoch:49
R_cost:1.84476  P_cost:6.21212  all_cost:8.05688
alpha:0.21938

*************************************
t9:
input_number:5000
n_epoch:1000
alpha:0.8
ela:0.001
learning_rate:10
u:0.005
alpha_learning_rate:0.001
-------------------------------------
epoch:0
R_cost:104.999  P_cost:18.2537  all_cost:123.253
epoch:49
R_cost:1.12467  P_cost:5.73547  all_cost:6.86015
alpha:0.205902
epoch:499
R_cost:0.633764 P_cost:4.51839  all_cost:5.15216
alpha:0.162725
epoch:999
R_cost:0.547294 P_cost:4.36366  all_cost:4.91095
alpha:0.16555
w_absolute_changes:1.25182  w_absolute_changes_all:17.1153
w_relative_changes:1.79251  w_relative_changes_all:24.8373

接下来的将learning_rate提高到了50训练了1000个，其他参数保持不变
lr50_a0.8_l0.001afterlr10.out
epoch:1000
R_cost:0.666939 P_cost:4.47 all_cost:5.13693
alpha:0.16555
w_absolute_changes:1.34969  w_absolute_changes_all:17.1335
w_relative_changes:1.34969  w_relative_changes_all:17.1335
epoch:1699
R_cost:0.559682 P_cost:4.31809  all_cost:4.87777
alpha:0.174501
w_absolute_changes:1.12979  w_absolute_changes_all:15.5469
w_relative_changes:1.37929  w_relative_changes_all:22.0679
epoch:1999
R_cost:0.463319 P_cost:4.19754  all_cost:4.66086
alpha:0.175592
bsolute_changes:0.658341 w_absolute_changes_all:14.1764
w_relative_changes:1.10886  w_relative_changes_all:21.7238

接下来将lr提升到了100，训练了1000个
lr100_a0.8_l0.001afterlr50.out
epoch:2000   t10
R_cost:0.556253 P_cost:4.29494  all_cost:4.8512
w_absolute_changes:1.09049  w_absolute_changes_all:15.296
w_relative_changes:1.09049  w_relative_changes_all:15.296
epoch:2999
R_cost:0.469827 P_cost:4.20839  all_cost:4.67822
alpha:0.17715
w_absolute_changes:0.729629 w_absolute_changes_all:13.6186
w_relative_changes:1.13747  w_relative_changes_all:19.3473

在2000的基础上，将lr提升到100，lambda提升到0.01，训练1000个
epoch:2000    t11
R_cost:0.549567 P_cost:43.0329  all_cost:43.5825
w_absolute_changes:3.68863  w_absolute_changes_all:81.9894
w_relative_changes:3.68863  w_relative_changes_all:81.9894
epoch:2999
R_cost:11.933   P_cost:14.2818  all_cost:26.2148
alpha:0.0361606
w_absolute_changes:0.881758 w_absolute_changes_all:20.0209
w_relative_changes:1.25632  w_relative_changes_all:28.6461

lambda提升到0.005
lr100_a0.8_l0.005afterlr50.out
epoch:2000    t12
R_cost:0.549567 P_cost:21.5165  all_cost:22.066
w_absolute_changes:1.83985  w_absolute_changes_all:37.9745
w_relative_changes:1.83985  w_relative_changes_all:37.9745
epoch:2499
R_cost:4.86774  P_cost:12.2933  all_cost:17.1611
alpha:0.0728683
w_absolute_changes:0.972201 w_absolute_changes_all:22.5526
w_relative_changes:1.45805  w_relative_changes_all:34.0005

然后将lr提升到500，训练了1000个，发现没变化
lr500_a0.8_l0.001afterlr100.out
epoch:3000
R_cost:0.535573 P_cost:4.27189  all_cost:4.80746
w_absolute_changes:0.894248 w_absolute_changes_all:13.2398
w_relative_changes:0.894248 w_relative_changes_all:13.2398
epoch:3999
R_cost:0.450297 P_cost:4.15238  all_cost:4.60268
alpha:0.177679
w_absolute_changes:0.287605 w_absolute_changes_all:7.02393
w_relative_changes:0.476733 w_relative_changes_all:10.7414

在lr为100之后，尝试将lambda调大到0.01，发现没变化（与lr500一样），但是调到0.1就会迅速的变成nan，接下来尝试训练lr50后的数据(调错了，此处改变的是alpha的learning rate)
lr50_a0.8_l0.01afterlr100.out




*************************************
t2: lr3_l0.005.out
input_number:5000
n_epoch:50
alpha:0.35
ela:0.01
learning_rate:3
u:0.005
alpha_learning_rate:0.001
--------------------------------------
epoch:0
R_cost:18.4644  P_cost:80.0917  all_cost:98.556
epoch:49
R_cost:7.38394  P_cost:12.128   all_cost:19.512
alpha:0.0538119
训练出部分特征，特征收敛较快

***************************************
t3: lr5_l0.01.out
input_number:5000
n_epoch:1000
alpha:0.8
ela:0.01
learning_rate:5
u:0.005
alpha_learning_rate:0.0005
----------------------------------------
epoch:0
R_cost:108.905  P_cost:184.086  all_cost:292.99
epoch:49
R_cost:30.0376  P_cost:6.2753   all_cost:36.3129
alpha:0.0403823
epoch:336
R_cost:22.2071  P_cost:8.21818  all_cost:30.4252
alpha:0.063062
特征收敛较快

****************************************
t4: lr10_l0.01.out
input_number:5000
n_epoch:1000
alpha:0.8
ela:0.01
learning_rate:10
u:0.005
alpha_learning_rate:0.0005
----------------------------------------
epoch:0
R_cost:105.472  P_cost:183.866  all_cost:289.338
epoch:49
R_cost:30.155   P_cost:5.2642   all_cost:35.4192
alpha:0.0590719
epoch:323
R_cost:27.1367  P_cost:5.6468   all_cost:32.7835
alpha:0.0854014















